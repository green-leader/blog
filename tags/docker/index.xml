<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>docker on Blog</title><link>https://blog.sions.org/tags/docker/</link><description>Recent content in docker on Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 20 Mar 2023 08:00:00 +0000</lastBuildDate><atom:link href="https://blog.sions.org/tags/docker/index.xml" rel="self" type="application/rss+xml"/><item><title>Full Hd</title><link>https://blog.sions.org/posts/full-hd/</link><pubDate>Mon, 20 Mar 2023 08:00:00 +0000</pubDate><guid>https://blog.sions.org/posts/full-hd/</guid><description>I woke up this morning to my RSS feed misbehaving. FreshRSS was popping up an error along the lines that it was unable to make an internet connection. This was a little odd as I was connected over the local network to the app. It was loading at all which meant it could connect. I won&amp;rsquo;t bore you with how I found the problem, but the root partition of the server was full.</description><content>&lt;p>I woke up this morning to my RSS feed misbehaving. FreshRSS was popping up an error along the lines that it was unable to make an internet connection. This was a little odd as I was connected over the local network to the app. It was loading at all which meant it could connect. I won&amp;rsquo;t bore you with how I found the problem, but the root partition of the server was full.&lt;/p>
&lt;p>A full root partition can cause a wide array of problems. As there shouldn&amp;rsquo;t be anything downloading to this partition it was well over what it should be. The root partition is located on a 112 GB SSD. so there&amp;rsquo;s not a whole lot but after cleaning up space I found that I was using less than a quarter of the drive.&lt;/p>
&lt;p>When the drive is full you need to prioritze geting any space. just so the system can start to breathe again.&lt;/p>
&lt;p>As this is a docker host &lt;code>docker system prune&lt;/code> is a great candidate. It only cleared off a few hundred megs but it did what it was supposed to in this instance. Now we can search down and track down what the issue is.&lt;/p>
&lt;p>&lt;code>sudo du -hsx /* | sort -rh | head -n 5&lt;/code>
Couple things going on so lets break down the arguments
&lt;code>du -hsx&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>h&lt;/code>: Human readable output. As a lowly human just reading bytes is hard.&lt;/li>
&lt;li>&lt;code>s&lt;/code>: summarize, just put the totals on everything that du is ran against.&lt;/li>
&lt;li>&lt;code>x&lt;/code>: one-file-system. Don&amp;rsquo;t leave the filesystem, as we are only looking at the root partiition we don&amp;rsquo;t need to know about everything that&amp;rsquo;s mounted within the &lt;code>/&lt;/code> filesystem.&lt;/li>
&lt;/ul>
&lt;p>&lt;code>sort -rh&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>r&lt;/code>: Reverse. We want the big numbers first&lt;/li>
&lt;li>&lt;code>h&lt;/code>: human-numeric-sort. We&amp;rsquo;re using human numbers because we&amp;rsquo;re human.&lt;/li>
&lt;/ul>
&lt;p>&lt;code>head -n 10&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>n&lt;/code>: Pretty simple, this is how many lines we want. By specifying a number we&amp;rsquo;re not just using the default.&lt;/li>
&lt;/ul>
&lt;p>And the output:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ sudo du -hsx /* | sort -rh | head -n &lt;span style="color:#ae81ff">5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>86G /var
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>3.2G /home
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>2.0G /usr
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>81M /boot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>3.9M /etc
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Well it&amp;rsquo;s &lt;code>/var&lt;/code> as a culprit. We can just run the same command but specifying the path so we can dig in and keep digging down to find where the issue is. I won&amp;rsquo;t post the outputs but I&amp;rsquo;ll give the commands:&lt;/p>
&lt;ol>
&lt;li>&lt;code>$ sudo du -hsx /var/* | sort -rh | head -n 5&lt;/code>&lt;/li>
&lt;li>&lt;code>$ sudo du -hsx /var/lib/* | sort -rh | head -n 5&lt;/code>&lt;/li>
&lt;li>&lt;code>$ sudo du -hsx /var/lib/docker/* | sort -rh | head -n 5&lt;/code>&lt;/li>
&lt;li>&lt;code>$ sudo du -hsx /var/lib/docker/containers/* | sort -rh | head -n 5&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>And the output for that last command points where the culprit is, mainly this nifty line:&lt;code>64G /var/lib/docker/containers/containers/c585fa6366ddbd90e8565e07797431deab5c86bd157f757317d3b0655c099562&lt;/code>&lt;/p>
&lt;p>Looking a bit further (I forgot to grab logs of my commands) we can see that the container log(s) is a single 63 gig file. Whelp. There&amp;rsquo;s the problem. A single docker container log is eating up 64 gigs of data, probaly bad configuration on my part. Using &lt;code>docker inspect&lt;/code> we can find out which container was badly configured. Ended up being my borgmatic container, which has been running daily for over a month. Great! A log file is an easy fix! We just need to implement log rotation.&lt;/p>
&lt;p>Couple different ways we can do it.&lt;/p>
&lt;ul>
&lt;li>logrotate daemon&lt;/li>
&lt;li>docker daemon log-driver settings&lt;/li>
&lt;/ul>
&lt;p>The docker daemon is probably a little easier to configure, but I&amp;rsquo;m also just more comfortable with it. Setting defaults on the docker stuff is primarily done via the config file which on a linux system is at &lt;code>/etc/docker/daemon.json&lt;/code>. This file may need to be created, and we&amp;rsquo;ll do so putting the below into the file. Updating this file and restarting the service via &lt;code>sudo systemctl restart docker.service&lt;/code> will cause any new container to use these new logging driver settings. As this isn&amp;rsquo;t a new container we&amp;rsquo;ll just use &lt;code>docker-compose down&lt;/code> followed by &lt;code>docker-compose up -d&lt;/code> on the compose file with the culprit container.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;log-driver&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;local&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;log-opts&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;max-size&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;15m&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;max-file&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;5&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>After updating these settings we can see that was the issue &lt;code>df -h&lt;/code> is now reporting that the root partition is at 27G which is much much better. Should figure out how to send logs to splunk. Though I&amp;rsquo;m not sure I like using splunk. We should also set up monitoring to get a notification when we get close to filling the drive again.&lt;/p></content></item><item><title>Publishing Obsidian Documentation</title><link>https://blog.sions.org/posts/docs-publishing/</link><pubDate>Mon, 27 Feb 2023 05:33:12 +0000</pubDate><guid>https://blog.sions.org/posts/docs-publishing/</guid><description>I keep my notes in markdown files in a git repo my primary editor is a tool called obsidian.md. I&amp;rsquo;ve got minor gripes and for the most part I&amp;rsquo;ve got it syncing well and working well. However, a nice to have feature would be to share individual documents with the public. Couple examples, keeping a digital recipe box for the household to read from or sharing TTRPG notes after a session.</description><content>&lt;p>I keep my notes in markdown files in a git repo my primary editor is a tool called &lt;a href="https://obsidian.md/">obsidian.md&lt;/a>. I&amp;rsquo;ve got minor gripes and for the most part I&amp;rsquo;ve got it syncing well and working well. However, a nice to have feature would be to share individual documents with the public. Couple examples, keeping a digital recipe box for the household to read from or sharing TTRPG notes after a session.&lt;/p>
&lt;p>For right now I want to set it up such that I can share things with the household. Log into the designated subdomain, and so long as you&amp;rsquo;re on my network using my DNS server it should load happily.&lt;/p>
&lt;p>Here&amp;rsquo;s the process I&amp;rsquo;ve taken and settled on for now.&lt;/p>
&lt;p>Workflow:&lt;/p>
&lt;ol>
&lt;li>sync git repo&lt;/li>
&lt;li>process markdown into HTML&lt;/li>
&lt;li>serve HTML with a web server&lt;/li>
&lt;/ol>
&lt;p>Tools:&lt;/p>
&lt;ol>
&lt;li>Githubs cli tool &lt;a href="https://github.com/cli/cli">github.com/cli/cli&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/devidw/obsidian-to-hugo">obsidian-to-hugo&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gohugo.io/">hugp&lt;/a>&lt;/li>
&lt;li>nginx running on docker&lt;/li>
&lt;/ol>
&lt;h3 id="workflow-step-1">Workflow Step 1:&lt;/h3>
&lt;p>Something I&amp;rsquo;ve been trying to deal with and come up with a solution I like is giving my server read-only access to multiple private repos. As of the time of this writing I keep most of my git repositories located at github. Github doesn&amp;rsquo;t allow you to specify an ssh key as a deploy key to multiple projects. And the deploy keys work great if you only need to grant access to 1 repo. But this runs into problems when you&amp;rsquo;re trying to grant access to several, purely from a management standpoint. how you do you cleanly associate an ssh key with individual repos then refer to them. I saw some hacks online but I hadn&amp;rsquo;t liked any of them.&lt;/p>
&lt;p>Doing a bit of experimenting on this when I was trying to deploy this I remembered the Github CLI tool. After some trial and error I found that you can not use a personal access token however neither fine-grained tokens or classic tokens seem to have access to just perform read-only actions on the content of repos. I ended up using http authentication, logging in as myself. While writing this I&amp;rsquo;m trying to think if it&amp;rsquo;s got read-only access or full read-write. I&amp;rsquo;ll have to investigate it later.&lt;/p>
&lt;h3 id="workflow-step-2">Workflow Step 2:&lt;/h3>
&lt;p>Processing markdown files into HTML is a joint problem. There&amp;rsquo;s a number of static site generators that will take in markdown and output HTML. The tool i&amp;rsquo;m most familiar with is hugo, which is what this blog is using. Doing a bit of research I found a python module that converts obsidian markdown files into hugo markdown files.&lt;/p>
&lt;p>looking at the readme it also provides functionality on scanning the contents of the file for specific conditions as to whether it should graduate into a published document. I&amp;rsquo;ve got a small python script written below which I run before I have hugo process the documents into HTML.&lt;/p>
&lt;p>process.py:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> obsidian_to_hugo &lt;span style="color:#f92672">import&lt;/span> ObsidianToHugo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">filter_file&lt;/span>(file_contents: str, file_path: str) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> bool:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#e6db74">&amp;#34;publish: true&lt;/span>&lt;span style="color:#ae81ff">\n&lt;/span>&lt;span style="color:#e6db74">---&amp;#34;&lt;/span> &lt;span style="color:#f92672">in&lt;/span> file_contents:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">True&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#e6db74">&amp;#34;template_&amp;#34;&lt;/span> &lt;span style="color:#f92672">in&lt;/span> file_path:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>obsidian_to_hugo &lt;span style="color:#f92672">=&lt;/span> ObsidianToHugo(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> obsidian_vault_dir&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/local/kb-obsidian&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hugo_content_dir&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/local/hugo-site/content&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> filters&lt;span style="color:#f92672">=&lt;/span>[filter_file],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>obsidian_to_hugo&lt;span style="color:#f92672">.&lt;/span>run()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is a pretty strightforward snippet on the python projects readme I&amp;rsquo;ve adjusted a bit for my needs.&lt;/p>
&lt;p>After generating the content with that processing script we now need to trigger hugo to run and convert the content markdown files into HTML. Creating and configuring the initial hugo site only needs to be done the first time, but after that you can just change to the hugo site directory, then execute a simple &lt;code>hugo&lt;/code>. Depending on which theme you&amp;rsquo;re using it could require the extended version of hugo. Below I&amp;rsquo;ve included my config file.&lt;/p>
&lt;p>When taking notes I will add page links to pages that don&amp;rsquo;t exist. This can cause hugo to throw a fit and refuse to process then the files.
&lt;code>REF_NOT_FOUND: Ref &amp;quot;Azure&amp;quot;: &amp;lt;snip&amp;gt;: page not found&lt;/code>&lt;/p>
&lt;p>Adding &lt;code>refLinksErrorLevel = &amp;quot;WARNING&amp;quot;&lt;/code> to the config file results in warnings still being emitted but will tell hugo that it&amp;rsquo;s alright.&lt;/p>
&lt;p>hugo config.toml&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-toml" data-lang="toml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">baseURL&lt;/span> = &lt;span style="color:#e6db74">&amp;#39;/&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">languageCode&lt;/span> = &lt;span style="color:#e6db74">&amp;#39;en-us&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">title&lt;/span> = &lt;span style="color:#e6db74">&amp;#39;My New Hugo Site&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">theme&lt;/span> = &lt;span style="color:#e6db74">&amp;#39;ananke&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">refLinksErrorLevel&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;WARNING&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="workflow-step-3">Workflow Step 3:&lt;/h3>
&lt;p>This is for the most part the simplest step, couple bullet points:&lt;/p>
&lt;ul>
&lt;li>Create a custom nginx config&lt;/li>
&lt;li>Point nginx at the hugo sites public directory&lt;/li>
&lt;li>Launch nginx container&lt;/li>
&lt;/ul>
&lt;p>I like to set the volume mounting and launch the container to create the directory structure. Replacing &lt;code>nginx/nginx/site-confs/default.conf&lt;/code> with our custom config.&lt;/p>
&lt;p>nginx config file&lt;/p>
&lt;pre tabindex="0">&lt;code>server {
listen 80 default_server;
listen [::]:80 default_server;
server_name _;
set $root /app/www/public;
if (!-d /app/www/public) {
set $root /config/www;
}
root $root;
index index.HTML;
location / {
try_files $uri $uri/ /index.HTML /index.php$is_args$args =404;
add_header &amp;#39;Access-Control-Allow-Origin&amp;#39; &amp;#39;*&amp;#39;; # Allow access to resources (for www and non www)
}
}
&lt;/code>&lt;/pre>&lt;p>docker-compose.yml&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;2.1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">services&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">nginx-docs&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">lscr.io/linuxserver/nginx:latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">env_file&lt;/span>: &lt;span style="color:#ae81ff">.env&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./nginx:/config&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./hugo-site/public:/config/www&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">3003&lt;/span>:&lt;span style="color:#ae81ff">80&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">restart&lt;/span>: &lt;span style="color:#ae81ff">unless-stopped&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">mgmt_network&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.enable=true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs-http.entrypoints=web&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs-http.rule=Host(`docs.${DOMAIN}`)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs-http.middlewares=docs-https&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.middlewares.docs-https.redirectscheme.scheme=https&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs.entrypoints=websecure&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs.rule=Host(`docs.${DOMAIN}`)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs.tls=true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs.tls.certresolver=myresolver&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.services.docs.loadbalancer.server.port=80&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">mgmt_network&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">external&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now when someone on the wifi goes the the subdomain docs on my internal domain name they get served the default hugo index page. There&amp;rsquo;s no sitemap, but if things link to each other correctly it&amp;rsquo;s plenty user friendly. While it&amp;rsquo;s not pretty it&amp;rsquo;s a minimum viable product and I plan to further iterate on it.&lt;/p></content></item><item><title>Splunk Setup</title><link>https://blog.sions.org/posts/splunk-setup/</link><pubDate>Mon, 20 Feb 2023 03:24:33 +0000</pubDate><guid>https://blog.sions.org/posts/splunk-setup/</guid><description>I set up a splunk docker container recently and there were a couple what feel like oddities catching me up.
Default debian doesn&amp;rsquo;t have world readable log files. This is not for production. But it&amp;rsquo;s okay for my homelab. Starting with this basic docker-compose file we made sure it worked.
version: &amp;#34;3.6&amp;#34; services: so1: image: ${SPLUNK_IMAGE:-splunk/splunk:latest} container_name: so1 environment: - SPLUNK_START_ARGS=--accept-license - SPLUNK_PASSWORD ports: - 8000:8000 It&amp;rsquo;s simple, gets everything running without doing anything fancy.</description><content>&lt;p>I set up a splunk docker container recently and there were a couple what feel like oddities catching me up.&lt;/p>
&lt;ol>
&lt;li>Default debian doesn&amp;rsquo;t have world readable log files.&lt;/li>
&lt;li>This is not for production. But it&amp;rsquo;s okay for my homelab.&lt;/li>
&lt;/ol>
&lt;p>Starting with this basic docker-compose file we made sure it worked.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;3.6&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">services&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">so1&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">${SPLUNK_IMAGE:-splunk/splunk:latest}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">container_name&lt;/span>: &lt;span style="color:#ae81ff">so1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">environment&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">SPLUNK_START_ARGS=--accept-license&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">SPLUNK_PASSWORD&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">8000&lt;/span>:&lt;span style="color:#ae81ff">8000&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It&amp;rsquo;s simple, gets everything running without doing anything fancy. Let&amp;rsquo;s iterate it fancier and match the style of the rest of my compose files.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;3.6&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">services&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">splunk&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">splunk/splunk:latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">container_name&lt;/span>: &lt;span style="color:#ae81ff">splunk&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">env_file&lt;/span>: &lt;span style="color:#ae81ff">.env&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">environment&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">SPLUNK_START_ARGS=--accept-license&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">splunk_config:/opt/splunk/etc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">splunk_data:/opt/splunk/var&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">/var/log:/host/var/log:ro&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">8000&lt;/span>:&lt;span style="color:#ae81ff">8000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">restart&lt;/span>: &lt;span style="color:#ae81ff">unless-stopped&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">mgmt_network&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.enable=true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk-http.entrypoints=web&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk-http.rule=Host(`splunk.${DOMAIN}`)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk-http.middlewares=splunk-https&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.middlewares.splunk-https.redirectscheme.scheme=https&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk.entrypoints=websecure&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk.rule=Host(`splunk.${DOMAIN}`)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk.tls=true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.secwhoami.tls.certresolver=myresolver&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.services.splunk.loadbalancer.server.port=8000&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">splunk_config&lt;/span>: {}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">splunk_data&lt;/span>: {}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">mgmt_network&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">external&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is what we end up with after a couple iterations. But largely it matches the style and layout of the rest of my compose files. Three large changes:&lt;/p>
&lt;ol>
&lt;li>I&amp;rsquo;ve moved the splunk password out of the compose file to a .env file (which gets encrypted for storing in git)&lt;/li>
&lt;li>Added data persistence&lt;/li>
&lt;li>Added Traefik labels, and network traefik watches&lt;/li>
&lt;/ol>
&lt;p>There was a slight problem once this was done, all of the files in &lt;code>/var/log&lt;/code> aren&amp;rsquo;t world readable. After a bit of searching we come across the splunk community forums detailing a similar issue &lt;a href="https://community.splunk.com/t5/Security/How-to-monitor-root-owned-logs-while-running-Splunk-as-a-non/td-p/16594">community.splunk.com&lt;/a> while this isn&amp;rsquo;t a docker solution it&amp;rsquo;s a solution to the problem. If not the most docker centric approach it beats setting up a universal forwarder to get files to the same machine.&lt;/p>
&lt;p>Boiling it down we need to install acl controls, create a splunk user on the host, set up a logrotate rule file.&lt;/p>
&lt;h2 id="accomplishing-1-and-2">Accomplishing 1 and 2:&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo apt install acl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo groupadd -g &lt;span style="color:#ae81ff">41812&lt;/span> splunk
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo adduser --uid &lt;span style="color:#ae81ff">41812&lt;/span> splunk --shell /sbin/nologin --system --no-create-home --gid &lt;span style="color:#ae81ff">41812&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Notice we created a group then created the user. The version of debian I was running with the version of adduser I had wasn&amp;rsquo;t permitting to explicity specify that I needed a primary group matching the user. Making the user on its own was causing the user to get put in a group &amp;ldquo;nogroup&amp;rdquo;. Probably user error.&lt;/p>
&lt;h2 id="accomplishing-number-3">Accomplishing number 3:&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cat /etc/logrotate.d/Splunk_ACLs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/var/log/splunklog
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> postrotate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /usr/bin/setfacl -m g:splunk:r /var/log/auth.log
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /usr/bin/setfacl -m g:splunk:r /var/log/messages
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /usr/bin/setfacl -m g:splunk:r /var/log/syslog
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> endscript
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Understanding this fully needs a bit of background.&lt;/p>
&lt;h3 id="logrotate">logrotate&lt;/h3>
&lt;p>As a broad stroke logrotate has a simple task. Keep files manageable.&lt;/p>
&lt;p>logrotate performs this function through keeping track of the size of the file, or at regular intervals renames the file adding a &lt;code>.#&lt;/code> onto the end of the filename. The tool is capable of much more but we don&amp;rsquo;t want to delve too far into that.&lt;/p>
&lt;p>The directory &lt;code>/etc/logrotate.d/&lt;/code> is charged with holding different configurations for various packages. In this case we&amp;rsquo;ve both created a dummy file &lt;code>/var/log/splunklog&lt;/code> and listed various rules on how logrotate should interact with that file. By default this file will be run daily as the root user.&lt;/p>
&lt;h3 id="file-acls">File ACLs&lt;/h3>
&lt;p>The keywords &lt;code>postrotate&lt;/code> and &lt;code>endscript&lt;/code> desginate a block of actions that should be perfomed when the file &lt;code>Splunk_ACLs&lt;/code> is executed daily. This helps ensure that the specified actions are maintained on the specific files listed.&lt;/p>
&lt;p>Lets break down the line(s) &lt;code>/usr/bin/setfacl -m g:splunk:r /var/log/auth.log&lt;/code>&lt;/p>
&lt;ul>
&lt;li>&lt;code>/usr/bin/setfacl&lt;/code> is a command with the sole purpose of setting linux file ACL rules.&lt;/li>
&lt;li>&lt;code>-m&lt;/code> modify the rules on the designated file&lt;/li>
&lt;li>&lt;code>g:splunk:r&lt;/code> pretty simple. This is where we specify new rules that should be active on the file. &lt;code>:&lt;/code> is a delimiter splitting this into a three part spec.&lt;/li>
&lt;/ul>
&lt;p>that spec reads as follows:&lt;/p>
&lt;ul>
&lt;li>&lt;code>g&lt;/code> says that the following piece will be either a gid or a group name.&lt;/li>
&lt;li>&lt;code>splunk&lt;/code> the name of the group, we&amp;rsquo;re opting for readability by using a group name.&lt;/li>
&lt;li>&lt;code>r&lt;/code> the octal or relative form, if using relative any of &lt;code>rwx&lt;/code> can be used, we&amp;rsquo;ll be opting for read-only for logs in this case.&lt;/li>
&lt;/ul></content></item></channel></rss>