<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog</title><link>https://blog.sions.org/</link><description>Recent content on Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 15 Jul 2023 08:00:00 +0000</lastBuildDate><atom:link href="https://blog.sions.org/index.xml" rel="self" type="application/rss+xml"/><item><title>Image Change</title><link>https://blog.sions.org/posts/image-change/</link><pubDate>Sat, 15 Jul 2023 08:00:00 +0000</pubDate><guid>https://blog.sions.org/posts/image-change/</guid><description>While changing what source image a docker container in unRaid was using, the Docker managment service encountered an error. The error itself I forgot to write down. But what is normally a typical process of &amp;ldquo;download new image, stop old container. create new container, cleanup old image.&amp;rdquo; was interrupted and it left the container in a down state. This wasn&amp;rsquo;t good primarily because I am lazy and didn&amp;rsquo;t want to spend the mental power and try to come up with what the previous config options were so there can be no change except what image is being used.</description><content>&lt;p>While changing what source image a docker container in unRaid was using, the Docker managment service encountered an error. The error itself I forgot to write down. But what is normally a typical process of &amp;ldquo;download new image, stop old container. create new container, cleanup old image.&amp;rdquo; was interrupted and it left the container in a down state. This wasn&amp;rsquo;t good primarily because I am lazy and didn&amp;rsquo;t want to spend the mental power and try to come up with what the previous config options were so there can be no change except what image is being used.&lt;/p>
&lt;p>After fixing the underlying cause for what caused the error. (The ghcr package for this particular repo was marked as private only). I started trying to recover what was a downed service. A brief spat of web searches and I discover that when creating a custom docker image 2 things are true. The first that it&amp;rsquo;s stored as an xml template in &lt;code>/boot/config/plugins/dockerMan/templates-user&lt;/code>. The second that I didn&amp;rsquo;t have to open the XML file and try to transcode as I had thought. You can simply go to &lt;code>Docker&lt;/code> -&amp;gt; &lt;code>Add Container&lt;/code> -&amp;gt; &lt;code>Templates&lt;/code> and all of your custom docker invocations are contained there as templates. Easy Peasy.&lt;/p></content></item><item><title>Unraid Scripts</title><link>https://blog.sions.org/posts/unraid-scripts/</link><pubDate>Wed, 05 Jul 2023 08:00:00 +0000</pubDate><guid>https://blog.sions.org/posts/unraid-scripts/</guid><description>One of the services my unRaid box runs is a borgbackup server (which is secretly just an SSH server with a forced command). As a check to make sure the important repos are indeed getting backed up to I&amp;rsquo;ve got a script running daily via the User Scripts Plugin. It&amp;rsquo;s a pretty simple script, all it does is check when the files in certain target repos have last been written to.</description><content>&lt;p>One of the services my unRaid box runs is a borgbackup server (which is secretly just an SSH server with a forced command). As a check to make sure the important repos are indeed getting backed up to I&amp;rsquo;ve got a script running daily via the &lt;em>User Scripts&lt;/em> Plugin. It&amp;rsquo;s a pretty simple script, all it does is check when the files in certain target repos have last been written to. If it hasn&amp;rsquo;t been in the last 7 days we send a Discord message for awareness.&lt;/p>
&lt;p>Recently I was performing some maintenance and my script ran warning me that they all had not been written to within that cutoff. While I was investigating the logs it took me an embarrassingly long period of time to realize the unRaid array was simply not running. So, where the script was checking was missing. Time to add some safety to the script. Now the first section runs and the script will exit if the Array isnâ€™t running.&lt;/p>
&lt;p>Borg Check Script:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#!/bin/bash
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Check if array is started&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ls /mnt/disk&lt;span style="color:#f92672">[&lt;/span>1-9&lt;span style="color:#f92672">]&lt;/span>* 1&amp;gt;/dev/null 2&amp;gt;/dev/null
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> ! ls /mnt/disk&lt;span style="color:#f92672">[&lt;/span>1-9&lt;span style="color:#f92672">]&lt;/span>*
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">then&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> echo &lt;span style="color:#e6db74">&amp;#34;ERROR: Array must be started before using this script&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> exit
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>readonly WEBHOOK_URL&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;https://discord.com/api/webhooks/0000/XXXX&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># List of directories to check&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>readonly WATCH_DIRS&lt;span style="color:#f92672">=(&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;/mnt/dir1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;/mnt/dir2&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;/mnt/dir3&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Function to send a Discord webhook message&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>send_discord_message&lt;span style="color:#f92672">()&lt;/span> &lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> local message&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$1&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> local payload&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;{\&amp;#34;content\&amp;#34;: \&amp;#34;&lt;/span>$message&lt;span style="color:#e6db74">\&amp;#34;}&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> curl -H &lt;span style="color:#e6db74">&amp;#34;Content-Type: application/json&amp;#34;&lt;/span> -d &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$payload&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$WEBHOOK_URL&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Iterate over the directories&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> dir in &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>WATCH_DIRS[@]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>; &lt;span style="color:#66d9ef">do&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Check if any files were modified in the last 7 days&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> find &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$dir&lt;span style="color:#e6db74">&amp;#34;&lt;/span> -type f -newermt &lt;span style="color:#e6db74">&amp;#34;-7 days&amp;#34;&lt;/span> 2&amp;gt;/dev/null | grep -q .; &lt;span style="color:#66d9ef">then&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">continue&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">fi&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Send Discord webhook message for directories without recent changes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> MESSAGE&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Directory &lt;/span>$dir&lt;span style="color:#e6db74"> has not been modified in the last 7 days&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> send_discord_message &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$MESSAGE&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$MESSAGE&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">done&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></content></item><item><title>Full Hd</title><link>https://blog.sions.org/posts/full-hd/</link><pubDate>Mon, 20 Mar 2023 08:00:00 +0000</pubDate><guid>https://blog.sions.org/posts/full-hd/</guid><description>I woke up this morning to my RSS feed misbehaving. FreshRSS was popping up an error along the lines that it was unable to make an internet connection. This was a little odd as I was connected over the local network to the app. It was loading at all which meant it could connect. I won&amp;rsquo;t bore you with how I found the problem, but the root partition of the server was full.</description><content>&lt;p>I woke up this morning to my RSS feed misbehaving. FreshRSS was popping up an error along the lines that it was unable to make an internet connection. This was a little odd as I was connected over the local network to the app. It was loading at all which meant it could connect. I won&amp;rsquo;t bore you with how I found the problem, but the root partition of the server was full.&lt;/p>
&lt;p>A full root partition can cause a wide array of problems. As there shouldn&amp;rsquo;t be anything downloading to this partition it was well over what it should be. The root partition is located on a 112 GB SSD. so there&amp;rsquo;s not a whole lot but after cleaning up space I found that I was using less than a quarter of the drive.&lt;/p>
&lt;p>When the drive is full you need to prioritze geting any space. just so the system can start to breathe again.&lt;/p>
&lt;p>As this is a docker host &lt;code>docker system prune&lt;/code> is a great candidate. It only cleared off a few hundred megs but it did what it was supposed to in this instance. Now we can search down and track down what the issue is.&lt;/p>
&lt;p>&lt;code>sudo du -hsx /* | sort -rh | head -n 5&lt;/code>
Couple things going on so lets break down the arguments
&lt;code>du -hsx&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>h&lt;/code>: Human readable output. As a lowly human just reading bytes is hard.&lt;/li>
&lt;li>&lt;code>s&lt;/code>: summarize, just put the totals on everything that du is ran against.&lt;/li>
&lt;li>&lt;code>x&lt;/code>: one-file-system. Don&amp;rsquo;t leave the filesystem, as we are only looking at the root partiition we don&amp;rsquo;t need to know about everything that&amp;rsquo;s mounted within the &lt;code>/&lt;/code> filesystem.&lt;/li>
&lt;/ul>
&lt;p>&lt;code>sort -rh&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>r&lt;/code>: Reverse. We want the big numbers first&lt;/li>
&lt;li>&lt;code>h&lt;/code>: human-numeric-sort. We&amp;rsquo;re using human numbers because we&amp;rsquo;re human.&lt;/li>
&lt;/ul>
&lt;p>&lt;code>head -n 10&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>n&lt;/code>: Pretty simple, this is how many lines we want. By specifying a number we&amp;rsquo;re not just using the default.&lt;/li>
&lt;/ul>
&lt;p>And the output:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ sudo du -hsx /* | sort -rh | head -n &lt;span style="color:#ae81ff">5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>86G /var
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>3.2G /home
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>2.0G /usr
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>81M /boot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>3.9M /etc
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Well it&amp;rsquo;s &lt;code>/var&lt;/code> as a culprit. We can just run the same command but specifying the path so we can dig in and keep digging down to find where the issue is. I won&amp;rsquo;t post the outputs but I&amp;rsquo;ll give the commands:&lt;/p>
&lt;ol>
&lt;li>&lt;code>$ sudo du -hsx /var/* | sort -rh | head -n 5&lt;/code>&lt;/li>
&lt;li>&lt;code>$ sudo du -hsx /var/lib/* | sort -rh | head -n 5&lt;/code>&lt;/li>
&lt;li>&lt;code>$ sudo du -hsx /var/lib/docker/* | sort -rh | head -n 5&lt;/code>&lt;/li>
&lt;li>&lt;code>$ sudo du -hsx /var/lib/docker/containers/* | sort -rh | head -n 5&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>And the output for that last command points where the culprit is, mainly this nifty line:&lt;code>64G /var/lib/docker/containers/containers/c585fa6366ddbd90e8565e07797431deab5c86bd157f757317d3b0655c099562&lt;/code>&lt;/p>
&lt;p>Looking a bit further (I forgot to grab logs of my commands) we can see that the container log(s) is a single 63 gig file. Whelp. There&amp;rsquo;s the problem. A single docker container log is eating up 64 gigs of data, probaly bad configuration on my part. Using &lt;code>docker inspect&lt;/code> we can find out which container was badly configured. Ended up being my borgmatic container, which has been running daily for over a month. Great! A log file is an easy fix! We just need to implement log rotation.&lt;/p>
&lt;p>Couple different ways we can do it.&lt;/p>
&lt;ul>
&lt;li>logrotate daemon&lt;/li>
&lt;li>docker daemon log-driver settings&lt;/li>
&lt;/ul>
&lt;p>The docker daemon is probably a little easier to configure, but I&amp;rsquo;m also just more comfortable with it. Setting defaults on the docker stuff is primarily done via the config file which on a linux system is at &lt;code>/etc/docker/daemon.json&lt;/code>. This file may need to be created, and we&amp;rsquo;ll do so putting the below into the file. Updating this file and restarting the service via &lt;code>sudo systemctl restart docker.service&lt;/code> will cause any new container to use these new logging driver settings. As this isn&amp;rsquo;t a new container we&amp;rsquo;ll just use &lt;code>docker-compose down&lt;/code> followed by &lt;code>docker-compose up -d&lt;/code> on the compose file with the culprit container.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;log-driver&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;local&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;log-opts&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;max-size&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;15m&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;max-file&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;5&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>After updating these settings we can see that was the issue &lt;code>df -h&lt;/code> is now reporting that the root partition is at 27G which is much much better. Should figure out how to send logs to splunk. Though I&amp;rsquo;m not sure I like using splunk. We should also set up monitoring to get a notification when we get close to filling the drive again.&lt;/p></content></item><item><title>I got my Network+ last week</title><link>https://blog.sions.org/posts/boring-week/</link><pubDate>Mon, 13 Mar 2023 08:00:00 +0000</pubDate><guid>https://blog.sions.org/posts/boring-week/</guid><description>Didn&amp;rsquo;t post last week when I got it, guess I was feeling a little burnt out.
But hey, first certification. Can&amp;rsquo;t necessarily use it at this point yet but I&amp;rsquo;ve got it and during the course of studying for it I definitely found that a number of things make more sense. Even just browsing the Homelab subreddit last night I could tell I had a better understanding than I did a couple months ago.</description><content>&lt;p>Didn&amp;rsquo;t post last week when I got it, guess I was feeling a little burnt out.&lt;/p>
&lt;p>But hey, first certification. Can&amp;rsquo;t necessarily use it at this point yet but I&amp;rsquo;ve got it and during the course of studying for it I definitely found that a number of things make more sense. Even just browsing the Homelab subreddit last night I could tell I had a better understanding than I did a couple months ago.&lt;/p></content></item><item><title>Publishing Obsidian Documentation</title><link>https://blog.sions.org/posts/docs-publishing/</link><pubDate>Mon, 27 Feb 2023 05:33:12 +0000</pubDate><guid>https://blog.sions.org/posts/docs-publishing/</guid><description>I keep my notes in markdown files in a git repo my primary editor is a tool called obsidian.md. I&amp;rsquo;ve got minor gripes and for the most part I&amp;rsquo;ve got it syncing well and working well. However, a nice to have feature would be to share individual documents with the public. Couple examples, keeping a digital recipe box for the household to read from or sharing TTRPG notes after a session.</description><content>&lt;p>I keep my notes in markdown files in a git repo my primary editor is a tool called &lt;a href="https://obsidian.md/">obsidian.md&lt;/a>. I&amp;rsquo;ve got minor gripes and for the most part I&amp;rsquo;ve got it syncing well and working well. However, a nice to have feature would be to share individual documents with the public. Couple examples, keeping a digital recipe box for the household to read from or sharing TTRPG notes after a session.&lt;/p>
&lt;p>For right now I want to set it up such that I can share things with the household. Log into the designated subdomain, and so long as you&amp;rsquo;re on my network using my DNS server it should load happily.&lt;/p>
&lt;p>Here&amp;rsquo;s the process I&amp;rsquo;ve taken and settled on for now.&lt;/p>
&lt;p>Workflow:&lt;/p>
&lt;ol>
&lt;li>sync git repo&lt;/li>
&lt;li>process markdown into HTML&lt;/li>
&lt;li>serve HTML with a web server&lt;/li>
&lt;/ol>
&lt;p>Tools:&lt;/p>
&lt;ol>
&lt;li>Githubs cli tool &lt;a href="https://github.com/cli/cli">github.com/cli/cli&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/devidw/obsidian-to-hugo">obsidian-to-hugo&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gohugo.io/">hugp&lt;/a>&lt;/li>
&lt;li>nginx running on docker&lt;/li>
&lt;/ol>
&lt;h3 id="workflow-step-1">Workflow Step 1:&lt;/h3>
&lt;p>Something I&amp;rsquo;ve been trying to deal with and come up with a solution I like is giving my server read-only access to multiple private repos. As of the time of this writing I keep most of my git repositories located at github. Github doesn&amp;rsquo;t allow you to specify an ssh key as a deploy key to multiple projects. And the deploy keys work great if you only need to grant access to 1 repo. But this runs into problems when you&amp;rsquo;re trying to grant access to several, purely from a management standpoint. how you do you cleanly associate an ssh key with individual repos then refer to them. I saw some hacks online but I hadn&amp;rsquo;t liked any of them.&lt;/p>
&lt;p>Doing a bit of experimenting on this when I was trying to deploy this I remembered the Github CLI tool. After some trial and error I found that you can not use a personal access token however neither fine-grained tokens or classic tokens seem to have access to just perform read-only actions on the content of repos. I ended up using http authentication, logging in as myself. While writing this I&amp;rsquo;m trying to think if it&amp;rsquo;s got read-only access or full read-write. I&amp;rsquo;ll have to investigate it later.&lt;/p>
&lt;h3 id="workflow-step-2">Workflow Step 2:&lt;/h3>
&lt;p>Processing markdown files into HTML is a joint problem. There&amp;rsquo;s a number of static site generators that will take in markdown and output HTML. The tool i&amp;rsquo;m most familiar with is hugo, which is what this blog is using. Doing a bit of research I found a python module that converts obsidian markdown files into hugo markdown files.&lt;/p>
&lt;p>looking at the readme it also provides functionality on scanning the contents of the file for specific conditions as to whether it should graduate into a published document. I&amp;rsquo;ve got a small python script written below which I run before I have hugo process the documents into HTML.&lt;/p>
&lt;p>process.py:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> obsidian_to_hugo &lt;span style="color:#f92672">import&lt;/span> ObsidianToHugo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">filter_file&lt;/span>(file_contents: str, file_path: str) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> bool:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#e6db74">&amp;#34;publish: true&lt;/span>&lt;span style="color:#ae81ff">\n&lt;/span>&lt;span style="color:#e6db74">---&amp;#34;&lt;/span> &lt;span style="color:#f92672">in&lt;/span> file_contents:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">True&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#e6db74">&amp;#34;template_&amp;#34;&lt;/span> &lt;span style="color:#f92672">in&lt;/span> file_path:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>obsidian_to_hugo &lt;span style="color:#f92672">=&lt;/span> ObsidianToHugo(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> obsidian_vault_dir&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/local/kb-obsidian&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hugo_content_dir&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/local/hugo-site/content&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> filters&lt;span style="color:#f92672">=&lt;/span>[filter_file],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>obsidian_to_hugo&lt;span style="color:#f92672">.&lt;/span>run()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is a pretty strightforward snippet on the python projects readme I&amp;rsquo;ve adjusted a bit for my needs.&lt;/p>
&lt;p>After generating the content with that processing script we now need to trigger hugo to run and convert the content markdown files into HTML. Creating and configuring the initial hugo site only needs to be done the first time, but after that you can just change to the hugo site directory, then execute a simple &lt;code>hugo&lt;/code>. Depending on which theme you&amp;rsquo;re using it could require the extended version of hugo. Below I&amp;rsquo;ve included my config file.&lt;/p>
&lt;p>When taking notes I will add page links to pages that don&amp;rsquo;t exist. This can cause hugo to throw a fit and refuse to process then the files.
&lt;code>REF_NOT_FOUND: Ref &amp;quot;Azure&amp;quot;: &amp;lt;snip&amp;gt;: page not found&lt;/code>&lt;/p>
&lt;p>Adding &lt;code>refLinksErrorLevel = &amp;quot;WARNING&amp;quot;&lt;/code> to the config file results in warnings still being emitted but will tell hugo that it&amp;rsquo;s alright.&lt;/p>
&lt;p>hugo config.toml&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-toml" data-lang="toml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">baseURL&lt;/span> = &lt;span style="color:#e6db74">&amp;#39;/&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">languageCode&lt;/span> = &lt;span style="color:#e6db74">&amp;#39;en-us&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">title&lt;/span> = &lt;span style="color:#e6db74">&amp;#39;My New Hugo Site&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">theme&lt;/span> = &lt;span style="color:#e6db74">&amp;#39;ananke&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">refLinksErrorLevel&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;WARNING&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="workflow-step-3">Workflow Step 3:&lt;/h3>
&lt;p>This is for the most part the simplest step, couple bullet points:&lt;/p>
&lt;ul>
&lt;li>Create a custom nginx config&lt;/li>
&lt;li>Point nginx at the hugo sites public directory&lt;/li>
&lt;li>Launch nginx container&lt;/li>
&lt;/ul>
&lt;p>I like to set the volume mounting and launch the container to create the directory structure. Replacing &lt;code>nginx/nginx/site-confs/default.conf&lt;/code> with our custom config.&lt;/p>
&lt;p>nginx config file&lt;/p>
&lt;pre tabindex="0">&lt;code>server {
listen 80 default_server;
listen [::]:80 default_server;
server_name _;
set $root /app/www/public;
if (!-d /app/www/public) {
set $root /config/www;
}
root $root;
index index.HTML;
location / {
try_files $uri $uri/ /index.HTML /index.php$is_args$args =404;
add_header &amp;#39;Access-Control-Allow-Origin&amp;#39; &amp;#39;*&amp;#39;; # Allow access to resources (for www and non www)
}
}
&lt;/code>&lt;/pre>&lt;p>docker-compose.yml&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;2.1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">services&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">nginx-docs&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">lscr.io/linuxserver/nginx:latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">env_file&lt;/span>: &lt;span style="color:#ae81ff">.env&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./nginx:/config&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./hugo-site/public:/config/www&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">3003&lt;/span>:&lt;span style="color:#ae81ff">80&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">restart&lt;/span>: &lt;span style="color:#ae81ff">unless-stopped&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">mgmt_network&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.enable=true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs-http.entrypoints=web&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs-http.rule=Host(`docs.${DOMAIN}`)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs-http.middlewares=docs-https&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.middlewares.docs-https.redirectscheme.scheme=https&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs.entrypoints=websecure&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs.rule=Host(`docs.${DOMAIN}`)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs.tls=true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.docs.tls.certresolver=myresolver&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.services.docs.loadbalancer.server.port=80&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">mgmt_network&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">external&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now when someone on the wifi goes the the subdomain docs on my internal domain name they get served the default hugo index page. There&amp;rsquo;s no sitemap, but if things link to each other correctly it&amp;rsquo;s plenty user friendly. While it&amp;rsquo;s not pretty it&amp;rsquo;s a minimum viable product and I plan to further iterate on it.&lt;/p></content></item><item><title>Splunk Setup</title><link>https://blog.sions.org/posts/splunk-setup/</link><pubDate>Mon, 20 Feb 2023 03:24:33 +0000</pubDate><guid>https://blog.sions.org/posts/splunk-setup/</guid><description>I set up a splunk docker container recently and there were a couple what feel like oddities catching me up.
Default debian doesn&amp;rsquo;t have world readable log files. This is not for production. But it&amp;rsquo;s okay for my homelab. Starting with this basic docker-compose file we made sure it worked.
version: &amp;#34;3.6&amp;#34; services: so1: image: ${SPLUNK_IMAGE:-splunk/splunk:latest} container_name: so1 environment: - SPLUNK_START_ARGS=--accept-license - SPLUNK_PASSWORD ports: - 8000:8000 It&amp;rsquo;s simple, gets everything running without doing anything fancy.</description><content>&lt;p>I set up a splunk docker container recently and there were a couple what feel like oddities catching me up.&lt;/p>
&lt;ol>
&lt;li>Default debian doesn&amp;rsquo;t have world readable log files.&lt;/li>
&lt;li>This is not for production. But it&amp;rsquo;s okay for my homelab.&lt;/li>
&lt;/ol>
&lt;p>Starting with this basic docker-compose file we made sure it worked.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;3.6&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">services&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">so1&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">${SPLUNK_IMAGE:-splunk/splunk:latest}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">container_name&lt;/span>: &lt;span style="color:#ae81ff">so1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">environment&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">SPLUNK_START_ARGS=--accept-license&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">SPLUNK_PASSWORD&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">8000&lt;/span>:&lt;span style="color:#ae81ff">8000&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It&amp;rsquo;s simple, gets everything running without doing anything fancy. Let&amp;rsquo;s iterate it fancier and match the style of the rest of my compose files.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;3.6&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">services&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">splunk&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">splunk/splunk:latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">container_name&lt;/span>: &lt;span style="color:#ae81ff">splunk&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">env_file&lt;/span>: &lt;span style="color:#ae81ff">.env&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">environment&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">SPLUNK_START_ARGS=--accept-license&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">splunk_config:/opt/splunk/etc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">splunk_data:/opt/splunk/var&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">/var/log:/host/var/log:ro&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">8000&lt;/span>:&lt;span style="color:#ae81ff">8000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">restart&lt;/span>: &lt;span style="color:#ae81ff">unless-stopped&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">mgmt_network&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.enable=true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk-http.entrypoints=web&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk-http.rule=Host(`splunk.${DOMAIN}`)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk-http.middlewares=splunk-https&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.middlewares.splunk-https.redirectscheme.scheme=https&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk.entrypoints=websecure&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk.rule=Host(`splunk.${DOMAIN}`)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.splunk.tls=true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.routers.secwhoami.tls.certresolver=myresolver&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;traefik.http.services.splunk.loadbalancer.server.port=8000&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">splunk_config&lt;/span>: {}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">splunk_data&lt;/span>: {}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">networks&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">mgmt_network&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">external&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is what we end up with after a couple iterations. But largely it matches the style and layout of the rest of my compose files. Three large changes:&lt;/p>
&lt;ol>
&lt;li>I&amp;rsquo;ve moved the splunk password out of the compose file to a .env file (which gets encrypted for storing in git)&lt;/li>
&lt;li>Added data persistence&lt;/li>
&lt;li>Added Traefik labels, and network traefik watches&lt;/li>
&lt;/ol>
&lt;p>There was a slight problem once this was done, all of the files in &lt;code>/var/log&lt;/code> aren&amp;rsquo;t world readable. After a bit of searching we come across the splunk community forums detailing a similar issue &lt;a href="https://community.splunk.com/t5/Security/How-to-monitor-root-owned-logs-while-running-Splunk-as-a-non/td-p/16594">community.splunk.com&lt;/a> while this isn&amp;rsquo;t a docker solution it&amp;rsquo;s a solution to the problem. If not the most docker centric approach it beats setting up a universal forwarder to get files to the same machine.&lt;/p>
&lt;p>Boiling it down we need to install acl controls, create a splunk user on the host, set up a logrotate rule file.&lt;/p>
&lt;h2 id="accomplishing-1-and-2">Accomplishing 1 and 2:&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo apt install acl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo groupadd -g &lt;span style="color:#ae81ff">41812&lt;/span> splunk
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo adduser --uid &lt;span style="color:#ae81ff">41812&lt;/span> splunk --shell /sbin/nologin --system --no-create-home --gid &lt;span style="color:#ae81ff">41812&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Notice we created a group then created the user. The version of debian I was running with the version of adduser I had wasn&amp;rsquo;t permitting to explicity specify that I needed a primary group matching the user. Making the user on its own was causing the user to get put in a group &amp;ldquo;nogroup&amp;rdquo;. Probably user error.&lt;/p>
&lt;h2 id="accomplishing-number-3">Accomplishing number 3:&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cat /etc/logrotate.d/Splunk_ACLs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/var/log/splunklog
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> postrotate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /usr/bin/setfacl -m g:splunk:r /var/log/auth.log
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /usr/bin/setfacl -m g:splunk:r /var/log/messages
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /usr/bin/setfacl -m g:splunk:r /var/log/syslog
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> endscript
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Understanding this fully needs a bit of background.&lt;/p>
&lt;h3 id="logrotate">logrotate&lt;/h3>
&lt;p>As a broad stroke logrotate has a simple task. Keep files manageable.&lt;/p>
&lt;p>logrotate performs this function through keeping track of the size of the file, or at regular intervals renames the file adding a &lt;code>.#&lt;/code> onto the end of the filename. The tool is capable of much more but we don&amp;rsquo;t want to delve too far into that.&lt;/p>
&lt;p>The directory &lt;code>/etc/logrotate.d/&lt;/code> is charged with holding different configurations for various packages. In this case we&amp;rsquo;ve both created a dummy file &lt;code>/var/log/splunklog&lt;/code> and listed various rules on how logrotate should interact with that file. By default this file will be run daily as the root user.&lt;/p>
&lt;h3 id="file-acls">File ACLs&lt;/h3>
&lt;p>The keywords &lt;code>postrotate&lt;/code> and &lt;code>endscript&lt;/code> desginate a block of actions that should be perfomed when the file &lt;code>Splunk_ACLs&lt;/code> is executed daily. This helps ensure that the specified actions are maintained on the specific files listed.&lt;/p>
&lt;p>Lets break down the line(s) &lt;code>/usr/bin/setfacl -m g:splunk:r /var/log/auth.log&lt;/code>&lt;/p>
&lt;ul>
&lt;li>&lt;code>/usr/bin/setfacl&lt;/code> is a command with the sole purpose of setting linux file ACL rules.&lt;/li>
&lt;li>&lt;code>-m&lt;/code> modify the rules on the designated file&lt;/li>
&lt;li>&lt;code>g:splunk:r&lt;/code> pretty simple. This is where we specify new rules that should be active on the file. &lt;code>:&lt;/code> is a delimiter splitting this into a three part spec.&lt;/li>
&lt;/ul>
&lt;p>that spec reads as follows:&lt;/p>
&lt;ul>
&lt;li>&lt;code>g&lt;/code> says that the following piece will be either a gid or a group name.&lt;/li>
&lt;li>&lt;code>splunk&lt;/code> the name of the group, we&amp;rsquo;re opting for readability by using a group name.&lt;/li>
&lt;li>&lt;code>r&lt;/code> the octal or relative form, if using relative any of &lt;code>rwx&lt;/code> can be used, we&amp;rsquo;ll be opting for read-only for logs in this case.&lt;/li>
&lt;/ul></content></item><item><title>An Entry</title><link>https://blog.sions.org/posts/an-entry/</link><pubDate>Sat, 07 Jan 2023 05:33:12 +0000</pubDate><guid>https://blog.sions.org/posts/an-entry/</guid><description>My first post. Well my first actual post was supposed to be a log/ tutorial/ step by step/ whatever of setting up Jekyll and Backblaze and cloudflare. Well that was several days ago. Now I&amp;rsquo;m typing this, a quick draft within Google Keep. Turn it into Markdown tomorrow. Post it day after. But largely I&amp;rsquo;ve been dragging my feet, what&amp;rsquo;s the goal of this blog? Is there one? Does there need to be one?</description><content>&lt;p>My first post. Well my first &lt;em>actual&lt;/em> post was supposed to be a log/ tutorial/ step by step/ whatever of setting up Jekyll and Backblaze and cloudflare. Well that was several days ago. Now I&amp;rsquo;m typing this, a quick draft within Google Keep. Turn it into Markdown tomorrow. Post it day after. But largely I&amp;rsquo;ve been dragging my feet, what&amp;rsquo;s the goal of this blog? Is there one? Does there need to be one?&lt;/p></content></item><item><title>Hello World</title><link>https://blog.sions.org/posts/hello-world/</link><pubDate>Sun, 01 Jan 2023 17:56:42 +0000</pubDate><guid>https://blog.sions.org/posts/hello-world/</guid><description>hello world!</description><content>&lt;p>hello world!&lt;/p></content></item></channel></rss>